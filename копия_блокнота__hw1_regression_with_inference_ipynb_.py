# -*- coding: utf-8 -*-
"""Копия блокнота "HW1_Regression_with_inference.ipynb"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RIHWGH_uwuWsceZfbCEJmYBU7dLif_w0

# Домашнее задание №1

В этом домашнем задании вам предлагается обучить модель регрессии для предсказания стоимости автомобилей, а также реализовать веб-сервис для применения построенной модели на новых данных.

> Оценка за домашку = min(ваш балл, 10)

Задания, <font color='#9933CC'>выделенные фиолетовым</font>, требуют от вас написания кода.

А вопросы, <font color='#FF6600'>выделенные оранжевым</font>, текстового ответа.

Оцениваются как код, так и ответы на вопросы. Если нет одного и/или другого, то часть баллов за соответствующее задание без колебаний снимается.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import random
import seaborn as sns

random.seed(42)
np.random.seed(42)

"""Ниже ответьте на вопрос <font color='#FF6600'>
"Для чего фиксируем сиды в домашках?"</font>
"""

print("чтобы каждый раз при рандом выборе вывод были одинаковые числа, фиксируем")

"""# Часть 1 (2.5 балла + 0.75) | EDA

## Простейший EDA и обработка признаков (1.5 балла + 0.25)
"""

df_train = pd.read_csv('https://raw.githubusercontent.com/Murcha1990/MLDS_ML_2022/main/Hometasks/HT1/cars_train.csv')
df_test = pd.read_csv('https://raw.githubusercontent.com/Murcha1990/MLDS_ML_2022/main/Hometasks/HT1/cars_test.csv')

print("Train data shape:", df_train.shape)
print("Test data shape: ", df_test.shape)

"""(0.15 балла) <font color='#9933CC'>Отобразите 10 **случайных** строк тренировочного датасета</font>"""

# your code here
df_train.sample(10)

"""(0.1 балла) <font color='#9933CC'>Отобразите первые 5 и последние 5 объектов тестового датасета</font>"""

# your code here
df_test.head(5)
df_test.tail(5)

"""(0.1 балла) <font color='#9933CC'>Посчитайте основные статистики как по числовым, так и по категориальным столбцам для трейна и теста</font>.
> Подсказка: ``.describe()`` с нужным(и) аргументом(-ами)


"""

# your code here
df_train.describe(include='object')
df_test.describe(include='object')

"""(0.15 балла) <font color='#9933CC'>Посмотрите, есть ли в датасете пропуски.</font>

<font color='#FF6600'>Если есть, то в каких колонках?</font>
"""

# your code here
df_train.isna().sum()
df_test.isna().sum()

"""(0.1 балла) <font color='#9933CC'>Посмотрите, есть ли в трейне объекты с одинаковым признаковым описанием</font> (целевую переменную следует исключить). Если есть, то сколько?"""

# your code here
df_train.drop(columns=['fuel',	'seller_type',	'transmission',	'owner'])
df_train.duplicated().sum()

"""(0.15 балла) <font color='#9933CC'>Отобразите такие объекты</font>"""

# your code here
df_train[df_train.duplicated()]

"""
(0.15 балла) <font color='#9933CC'>Удалите повторяющиеся строки</font>. Если при одинаковом признаковом описании цены на автомобили отличаются, то оставьте первую строку по этому автомобилю"""

# your code here
df_train = df_train.drop_duplicates()

df_train.shape

"""(0.1 балла) Чтоб все было по красоте, <font color='#9933CC'>обновите индексы строк таким образом, чтобы они шли от 0 без пропусков</font>"""

# your code here
df_train.reset_index(drop=True, inplace=True)

"""Вы могли заметить, что с признаками ``mileage, engine, max_power и torque`` всё не слава богу. Давайте починим.

(0.25 балла) Задача такая:
<font color='#9933CC'>
* убрать единицы измерения для признаков ``mileage, engine, max_power``.
* кастануть эти столбцы столбцы к ``float``.
* удалить столбец ``torque``
</font>

> Все действия нужно производить над обоими датасетами

---
**Доп (0.25 балла):**
* <font color='#9933CC'>Вместо удаления признак `torque` разделите на два: собственно `torque` и `max_torque_rpm`.</font> Учтите единицы измерения. Они разные ☹
"""

df_train = df_train.astype({
    "mileage": str,
    "engine": str,
    "max_power": str,
    "torque": str
})

df_test = df_test.astype({
    "mileage": str,
    "engine": str,
    "max_power": str,
    "torque": str
})

for col in ['mileage', 'engine', 'max_power']:
    df_train[col] = df_train[col].str.extract(r'(\d+\.?\d*)').astype(float)

df_train['torque_val'] = df_train['torque'].str.extract(r'(\d+\.?\d*)').astype(float)
df_train['max_torque_rpm'] = df_train['torque'].str.extract(r'@ *(\d+)').astype(float)

df_train = df_train.drop(columns=['torque'])
for col in ['mileage', 'engine', 'max_power']:
    df_test[col] = df_test[col].str.extract(r'(\d+\.?\d*)').astype(float)

df_test['torque_val'] = df_test['torque'].str.extract(r'(\d+\.?\d*)').astype(float)
df_test['max_torque_rpm'] = df_test['torque'].str.extract(r'@ *(\d+)').astype(float)

df_test = df_test.drop(columns=['torque'])

"""(0.15 балла) <font color='#9933CC'>Заполните пропуски в столбцах медианами. Убедитесь, что после заполнения пропусков не осталось</font>

> Обратите внимание, что, по уму, нужно посчитать медиану по трейну и этим средним заполнять пропуски в тесте. Так же делаем, если, например, стандартизируем признаки.


"""

# your code here
df_train.fillna(df_train.median(numeric_only=True), inplace=True)
df_test.fillna(df_train.median(numeric_only=True), inplace=True)

"""
(0.1 балла) Теперь, когда не осталось пропусков, можно <font color='#9933CC'>преобразовать столбцы к более подходящим типам (``engnine`` и ``seats`` к int)
</font>

Ниже ответьте, <font color='#FF6600'>почему (хоть мы этого и не делаем) ``seats``, возможно, лучше сделать переменной категориальной, а не целочисленной.</font>"""

print("потому что кол-во сидений это как тип машины и не требует математические решения: найти медиану и т.д это бесмыленно")

# your code here
df_train = df_train.astype({
    "engine": "int",
    "seats": "int"
})
df_test = df_test.astype({
    "engine": "int",
    "seats": "int"
})

"""## Визуализации (1 балл + 0.5)

Визуализировать нам надо не так уж и много. Во-первых, хотелось бы, в принципе, увидеть как распределены значения признаков. Также хотелось бы понять, насколько признаки скоррелированы между собой и с целевой переменной. А ещё неплохо бы посмотреть, не оказалось ли так, что тестовые данные распределены иначе, чем трейн.

Этим всем и предлагаем вам заняться.

(0.25 балла) <font color='#9933CC'>Посторойте попарные распределения всех числовых признаков для трейна.</font>

> ``sns.paiplot()`` позволяет сделать это в одну строчку
"""

# your code here
numeric_cols = df_train.select_dtypes(include="number").columns
sns.pairplot(df_train[numeric_cols],diag_kind="kde")
plt.show()

"""Этот график не такой информативный, как можно было бы построить, беря признаки по отдельности. Но он позволяет сделать некоторые (возможно, далеко идущие) выводы. Впрочем, со многими из них (если не со всеми) вы бы справились умозрительно. Однако всегда приятно делать выводы, основываясь на данных.



* <font color='#FF6600'> Что можно сказать о связи предикторов с целевой переменной?
* А о корреляциях признаков? </font>

(0.25 балла) <font color='#9933CC'>Постройте pairplot по тестовым данным</font> и ответьте на вопрос <font color='#FF6600'>"Похожими ли оказались совокупности при разделении на трейн и тест?"</font>
"""

# your code here
sns.pairplot(df_test[numeric_cols], diag_kind='kde')
plt.show()
print('Похожими оказались')

"""(0.25 балла) <font color='#9933CC'>Для трейна давайте построим тепловую карту (heatmap из библиотеки seaborn) попарных корреляций числовых колонок</font>"""

# your code here
plt.figure(figsize=(10,10))
sns.heatmap(df_train[numeric_cols].corr(), annot=True, fmt= ".2f", cmap = 'coolwarm')
plt.show()

"""Ответьте, пожалуйста, на вопросы:
* <font color='#FF6600'>Какие 2 признака наименее скоррелированы между собой?</font>
* <font color='#FF6600'>Между какими наблюдается довольно сильная положительная линейная зависимость?</font>
* <font color='#FF6600'>Правильно ли, опираясь на данные, утверждать, что чем меньше год, тем, скорее всего, больше километров проехала машина к дате продажи.</font>
"""

print("1) year and engine , year and seats \n2)max_power, torque_val \n3)yes ")

"""(0.25 балла) <font color='#9933CC'> Отобразите диаграммe рассеяния для наиболее скореллированной пары **признаков** (на трейне) </font>"""

# your code here
df_train.plot.scatter(x='max_power',y='torque_val', c='orange')
plt.show()

"""# Часть 2 (1.25 балла) | Модель только на вещественных признаках

(0.05 балла) <font color='#9933CC'>В переменные ``y_train`` и ``y_test`` запишите значения целевых переменных. Столбцы ``selling_price`` из датафреймов необходимо удалить. Категориальные (все, кроме ``seats``) столбцы тоже.</font>
"""

y_train = df_train['selling_price']
X_train = df_train.select_dtypes(include=['number']).drop(columns=['selling_price'])

X_train.head()

y_test = df_test['selling_price']
X_test = df_test.select_dtypes(include=['number']).drop(columns=['selling_price'])

"""(0.2 балла) <font color='#9933CC'>Обучите классическую линейную регрессию с дефолтными параметрами. Посчтитайте $R^2$ и MSE для трейна и для теста</font>

**Замечание:** $R^2$ и MSE для трейна и для теста выводите везде, где требуется обучать модели, даже если в явном виде этого не просят. Иначе непонятно, как понять, насколько успешны наши эксперименты.
"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error as MSE
from sklearn.model_selection import train_test_split
model = LinearRegression()
model.fit(X_train, y_train)
y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)
mse_train = MSE(y_train, y_train_pred)
mse_test = MSE(y_test, y_test_pred)
r2_train = r2_score(y_train, y_train_pred)
r2_test = r2_score(y_test, y_test_pred)
print(f"Train: R² = {r2_train:.4f}, MSE = {mse_train:.4f}")
print(f"Test : R² = {r2_test:.4f}, MSE = {mse_test:.4f}")

"""Запомните правило:

> Использую линейную модель -- стандартизирую фичи

(0.25 балла) <font color='#9933CC'>Воспользуемся им</font>

"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
# your code here

"""Не очень результативно.

Зато уже сейчас можем интерпретировать модель. <font color='#FF6600'>"Какой признак оказался наиболее информативным в предсказании цены?"</font>
"""

# your code here

"""\(0.25 балла) <font color='#9933CC'>Теперь попробуем Lasso-регрессию.</font> Здесь и дальше обучайте модели на нормализованных признаках"""

from sklearn.linear_model import Lasso
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

lasso = Pipeline([
    ("model", Lasso(random_state=42))
])

lasso.fit(X_train, y_train)
y_pred = lasso.predict(X_test)

print(f"Lasso: R² = {r2_score(y_test, y_pred):.4f}, MSE = {MSE(y_test, y_pred):.4f}")

"""<font color='#FF6600'>Занулила ли L1-регуляризация с параметрами по умолчанию какие-нибудь веса? Почему же?</font>"""

# your code here

"""(0.25 балла) <font color='#9933CC'>Перебором по сетке (c 10-ю фолдами) подберите оптимальные параметры для Lasso-регрессии</font>

Вам пригодится класс [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).
"""

from sklearn.model_selection import GridSearchCV

param_grid = {"model__alpha": np.logspace(-3, 2, 50)}

grid_lasso = GridSearchCV(
    estimator=lasso,
    param_grid=param_grid,
    cv=10,
    scoring="r2",
    n_jobs=-1
)

grid_lasso.fit(X_train, y_train)

print("best alpha for Lasso:", grid_lasso.best_params_)
print("best R² (train):", grid_lasso.best_score_)
print("R² (test):", r2_score(y_test, grid_lasso.predict(X_test)))

"""<font color='#FF6600'>Сколько грид-сёрчу пришлось обучать моделей?</font>

<font color='#FF6600'>Какой коэффициент регуляризации у лучшей из перебранных моделей? Занулились ли какие-нибудь из весов при такой регуляризации?</font>
"""

# your code here

"""(0.25 балла) <font color='#9933CC'>Перебором по сетке (c 10-ю фолдами) подберите оптимальные параметры для [ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html)-регрессии</font>"""

from sklearn.linear_model import ElasticNet

elastic = Pipeline([
    ("model", ElasticNet(random_state=42))
])

param_grid = {
    "model__alpha": np.logspace(-3, 2, 20),
    "model__l1_ratio": np.linspace(0, 1, 10)
}
grid_elastic = GridSearchCV(
    estimator=elastic,
    param_grid=param_grid,
    cv=10,
    scoring="r2",
    n_jobs=-1
)

grid_elastic.fit(X_train, y_train)

print("best parametres ElasticNet:", grid_elastic.best_params_)
print("best R² (train):", grid_elastic.best_score_)
print("R² (test):", r2_score(y_test, grid_elastic.predict(X_test)))

"""<font color='#FF6600'>Какие гиперпараметры соответствуют лучшей из перебранных моделей?</font>"""

# your code here

"""Предлагаем вам оставить вам попытки заметно улучшить качество модели регуляризацией и перейти к следующей части задания.

# Часть 3 (0.75 балла) | Добавляем категориальные фичи

(0 баллов) <font color='#9933CC'>Из ``df_train`` удалите столбцы с целевой переменной и названием автомобиля.</font>
"""

# your code here
X_train_cat = df_train.drop(columns=['selling_price', 'name'])
X_train_cat.describe(include='object')

"""(0.5 балла) <font color='#9933CC'>Закодируйте категориалльные фичи и ``seats`` методом OneHot-кодирования</font>

> Обратите внимание, что во избежание мультиколлинеарности следует избавиться от одного из полученных столбцов при кодировании каждого признака методом OneHot.
"""

from sklearn.preprocessing import OneHotEncoder
encoder = OneHotEncoder(drop="first", sparse_output=False)
encoded = encoder.fit_transform(df_train[["seats"]])
X_encoded = np.hstack([df_train.drop(columns=["seats"]).values, encoded])

"""### Дополнительные визуализации (бонус 0.5 балла)

Если вам кажется, что мы не попросили вас нарисовать какие-то очень важные зависимости, нарисуйте их и поясните.
"""

plt.scatter(y_train, y_train_pred, alpha=0.7)
plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], color="red")
plt.xlabel("Реальные значения (y_train)")
plt.ylabel("Предсказанные значения (y_train_pred)")
plt.title("Train: реальные vs предсказанные")
plt.show()

plt.scatter(y_test, y_test_pred, alpha=0.7)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color="red")
plt.xlabel("Реальные значения (y_test)")
plt.ylabel("Предсказанные значения (y_test_pred)")
plt.title("Test: реальные vs предсказанные")
plt.show()

"""(0.25 балла) <font color='#9933CC'>Переберите параметр регуляризации `alpha` для гребневой (ridge) регрессии с помощью класса `GridSearchCV`.</font> В качестве параметров при объявлении GridSearchCV кроме модели укажите метрику качества $R^2$. Кроссвалидируйтесь по 10-ти фолдам.

<font color='#FF6600'>Удалось ли улучшить качество предсказаний?</font>
"""

from sklearn.linear_model import Ridge
from sklearn.compose import ColumnTransformer

ridge = Pipeline([
    ("model", Ridge(random_state=42))
])

param_grid = {"model__alpha": np.logspace(-3, 2, 50)}

grid_ridge = GridSearchCV(
    estimator=ridge,
    param_grid=param_grid,
    cv=10,
    scoring="r2",
    n_jobs=-1
)

grid_ridge.fit(X_train, y_train)

print("Лучший alpha для Ridge:", grid_ridge.best_params_)
print("Лучшая R² (train):", grid_ridge.best_score_)
print("R² (test):", r2_score(y_test, grid_ridge.predict(X_test)))

"""# Часть 4 - бонусная (2 балла) | Feature Engineering

В этой части домашнего задания вам предлагается проявить свою креативность для улучшения прогноза модели. Любые другие модели, кроме различных форм линейной (или полиномиальной) регресси, использовать запрещается. А значит, придется работать с признаками

**Что можно попробовать сделать?** (каждый пункт по 0.4 балла, но не больше 2-х баллов в сумме)

1.   *Сгенерировать новые признаки на основе уже существующих:*
    * посчитать произведения // частные признаков (кажется, что посчитать число "лошадей" на литр объема может быть полезно);
    * имеет смысл обратить внимание на визуализации в части с EDA (к примеру, зависимость цены от года выглядит квадратичной, а не линейной; значит, квадрат года нам, скорее всего, принесет больше пользы)

2.   *Добыть новые признаки:*
    * имеем название автомобиля, которое никак не используем (можно спарсить инфу о классе автомобиля или каких-то специфических опциях)
    * можно добавить пороговые признаки вроде "владелец третий или больше" и объединить признаки в некоторые осмысленные правила, например "первый или второй владелец и продавец официальный дилер" (подбирать пороги удобно по диаграммам рассеяния)

3.   *Поработать с уже имеющимися:*
    * далеко не факт, что заполнить пропуск медианой было лучшей идеей (как минимум, можно добавить dummy-столбец для модели, сигнализирующий, что раньше на месте медианы был пропуск -- там где он был, конечно); попробуйте другие способы филлинга;
    * мы не анализировали, есть ли в данных выбросы => никак выбросы не обрабатывали; наиболее простым и, тем не менее, довольно полезным вариантом нахождения выбросов могут послужить boxplot'ы для каждого столбца; что делать с выбросами думайте сами :) -- вариантов довольно много
    * мы толком не смотрели на таргет сам по себе; в нем тоже могут быть неожиданности -- стоит хотя бы проверить
    * можно заметить, что некоторые признаки распределены совсем не нормально; возможно их стоит отлогарифмировать

И так далее...

Feel Free to Try!
"""

# your code here
import datetime
df = pd.DataFrame({
    "year": [2010, 2015, 2018, 2020, 2012],
    "mileage": [150000, 80000, 50000, 20000, 120000],
    "engine_power": [120, 150, 200, 250, 100],
    "engine_volume": [1.6, 2.0, 2.5, 3.0, 1.4],
    "owner": [2, 1, 1, 2, 3],
    "price": [400000, 700000, 900000, 1200000, 350000]
})
df["power_per_litre"] = df["engine_power"] / df["engine_volume"]
current_year = datetime.datetime.now().year
df["car_age"] = current_year - df["year"]
df["mileage_per_year"] = df["mileage"] / df["car_age"]
df["year_squared"] = df["year"]**2
df["owner_3plus"] = (df["owner"] >= 3).astype(int)
df["is_new"] = (df["car_age"] < 3).astype(int)
df["engine_volume_filled"] = df["engine_volume"].fillna(df["engine_volume"].median())
df["engine_volume_missing"] = df["engine_volume"].isna().astype(int)
for col in ["mileage", "engine_power", "price"]:
    low, high = df[col].quantile([0.01, 0.99])
    df[col] = df[col].clip(low, high)
df["log_price"] = np.log1p(df["price"])
df

"""# Часть Бизнесовая (0.5 балла)

Заказчик просил вас посчитать кастомную метрику -- среди всех предсказанных цен на авто посчитать долю предиктов, отличающихся от реальных цен на эти авто не более чем на 10% (в одну или другую сторону)

<font color='#9933CC'>Сделайте это самостоятельно для лучшей из своих моделей</font>
"""

def business_metrics(y_true, y_pred):
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)

    rel_error = np.abs(y_pred - y_true) / y_true

    return np.mean(rel_error <= 0.10)

y_true = [100, 200, 300, 400, 500]
y_pred = [105, 180, 330, 390, 600]

print(business_metrics(y_true, y_pred))